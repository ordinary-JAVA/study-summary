1.Git
Git中HEAD 指向的版本就是当前版本 因此 git允许我们在版本的历史之间穿梭 使用命令git reset --hard commit_id
穿梭前 用git log 可以查看提交历史 以便确定要回退到哪个版本
要重返未来 用 git reflog 查看历史命令 以便要回到未来的哪个版本
工作区 init的工作目录
版本库 repository 
工作区中有一个隐藏目录 .git 这个不算工作区 而是 git的版本库
Git版本库里存了很多东西 其中最重要的就是称为stage(或者叫index)的暂存区 还有git为我们自动创建的第一个分支master 以及指向master的一个指针叫head


把文件往git版本库中添加的时候 是分两步执行的
第一步 git add 把文件添加进去 实际上就是把文件修改添加到暂存区
第二步 是用git commit 提交更改 实际上就是把暂存区的所有内容提交到当前分支
因为我们创建git版本库时 git自动为我们创建了唯一一个master分支 所以 现在
Git commit就是往 master分支上提交更改
你可以简单理解为 需要提交的文件修改 通通放到暂存区 然后一次性提交暂存区的所有修改
Git commit 只会commit git add的文件 
命令 git checkout -- readme.txt 意思就是 把readme.txt 文件在工作区的修改全部撤销 这里有两种情况 
一种readme.txt自修改后还没有被放到暂存区 现在 撤销修改就回到和版本库一模一样的状态
一种是readme.txt已经添加到暂存区后 又做了修改 现在 撤销修改就回到添加到暂存区后的状态
总之 就是让这个文件回到最近一次 git commit或 git add时的状态
Git reset命令既可以回退版本 也可以把暂存区的修改回退到工作区 当我们用head时 表示最新的版本 然后Git checkout -- 文件名  即可回退
Git reset --head commitId  回退到指定版本 commit可以由git reflog 获取
当想丢弃工作区的 修改时 用命令git checkout --file
当想丢弃暂存区的修改时 分两步 一 git reset head <file> 二 用命令git checkout --file
如果要撤销版本库的提交时 可以回退此版本 前提是没有push到远程

命令 git rm 用于删除一个文件 如果一个文件已经被提交到版本库 那么你永远不用担心误删 但是要小心 你只能恢复文件到最新版本 你会丢失最近一次提交后修改的内容



分支合并和冲突解决 
 主分支master我们不会去动 只会用于版本的发布 
各自在自己的分支上开发完成后 需要将开发的内容合并到主分支上去 这时候成为merge

一个新的开发人员 dev_zhang
进行文件 add commit操作
此时在小张的分支上多了一个commitId 这时候需要把这个小张修改的内容进行版本的发布 就是需要把小张的修改内容合并到 master分支上
合并操作 切换到master分支上 git merge dev_zhang
然后删除小张分支 git branch -d dev_zhang 分支未合并到master前删除分支会报错 除非强制性删除 -D

创建多人开发 
创建两个新的分支 git checkout -b 分支名
各自在自己的分支上对文件进行修改及commit
合并一个分支后 合并另一个分支会有冲突


2.Log4j

log4j与logback冲突
Org.slf4j.LoggerFactory.getLogger(class) 方法的逻辑就是通过classLoader查找所有的org.slf4j.impl.StaticLoggerBinder.class 并确定最终实际使用那一个
在classpath 下找到了多个staticloggerBinder 并自动选择logback的ContextSelectorStaticBinder 那么 此时slf4j-log4j12就不起作用 log.xml也不起作用了
那么 为什么会先加载logback的staticLoggerBinder 是因为classLoader的类加载机制 双亲委派模型 有关的 同一个classLoader对于同一个类只会加载一次 所以即使classPath下有多个staticLoggerBinder.class 也会只有一个被加载 而且在我们当前环境下恰好加载的是logback的staticLoggerBinder

3.Tomcat

基于java的web应用程序 servlet jsp页面 静态页面 类和其他资源的集合 它们可以用标准方式打包 并运行在来自多个供应商的多个容器中  web应用程序存在于结构化层次结构的目录中 该层次结构是由java servlet规范定义的 web应用程序的根目录包含直接存储或存储在子文件夹中的所有公共资源 比如图像 html页面等 构成 web应用由web组件(一组Java类库)html文件 静态资源文件 帮助类和库组成 
Tomcat服务器是一个免费的开放源代码的web应用服务器 
Tomcat是一个小型的轻量级应用服务器 在中小型系统和并发访问用户不是很多的场合下被普遍使用 是开发和调试jsp程序的首选 对于一个初学者来说可以这样认为 当一台机器上配置好Apache服务器 可利用它响应对html页面的访问请求 实际上Tomcat部分是Apache服务器的扩展 但它是独立运行的 所以当你运行Tomcat时 它实际上作为一个与Apache独立的进程单独运行的


项目中依赖访问其他项目
在Tomcat中添加虚拟路径

Deploy到私服
在本地pull代码

Tomcat中只有一个server 一个server可以由多个service 一个service可以有多个 connector和一个container 
Server掌管着整个Tomcat的生死大权
Service是对外提供服务的
Connector用于接受请求并将请求封装成request和response来处理
Container用于封装和管理servlet 以及具体处理request请求
一个请求发送到Tomcat之后 首先经过service 然后会交给我们的connector connector用于接收请求并将接受的请求封装为 request和response来具体处理 request和response封装之后再交由container进行处理 container处理完请求之后再返回给connector 最后在由connector通过socket将处理的结果返回给客户端 
Connector最底层使用的是socket来进行连接的 request和response是按照http协议来封装的 所以connector同时需要实现tcp/ip协议和http协议
Connector用于接收请求并封装成request和response 然后交给container进行处理container处理完之后再交给connector然后返回客户端


Connector就是使用protocolHandler来处理请求的 不同的protocolhandler 代表不同的连接类型 http11protocol使用的是普通的socket来连接的 http11nioprotocol使用的是niosocket来连接的 
其中protocolHandler由包含了三个部件 endpoint processor adapter
Endpoint用来处理底层socket的网络连接 processor用于将endpoint接收到的socket封装成request adapter用于将request 交给container进行具体的处理
Endpoint 由于是处理底层的socket网络连接 因此endpoint 是用来实现tcp/ip协议的 而processor用来实现http协议的 adapter将请求适配到servlet容器进行具体的处理
Endpoint的抽象实现abstractendpoint 里边定义了acceptor和asynctimeout两个内部类和一个handler接口 acceptor用于监听请求 asynctimeout 用于检查异步request的超时 handler用于处理接收到的socket 在内部调用processor进行处理

Container用于封装和管理servlet 以及处理具体request请求 在Container包含了4个子容器
Engine 引擎 用来管理多个站点 一个service最多只能有一个engine
Host 代表一个站点 也可以叫虚拟主机 通过配置host就可以添加站点
Context 代表一个应用程序 对应着平时开发的一套程序 或者一个web-inf目录以及下面的web.xml文件
Wrapper 每一wrapper封装着一个servlet
Context和host的区别是context表示一个应用 我们的Tomcat中默认的配置下webapps下的每一个文件夹目录都是一个context 其中root目录中存放着主应用 其他目录存放着子应用 而整个WebApps就是一个host站点
当http请求到达Tomcat server时 httpconnector 得到serversocket(accept()方法)然后调用最上层容器的invoke 方法 而所有的容器都继承自containerbase 所以实际上调用的是 containerBase.invoke 方法

4.RabbitMq

Rabbitmq是一个开源的amqp实现 服务器端用erlang语言编写 支持多种客户端 java...支持ajax 用于分布式系统中存储转发消息 在易用性 扩展性 高可用性方面表现不俗
Amqp高级消息队列协议 是应用层协议的一个开放标准 为面向消息的中间件设计 消息中间件主要用于组件之间的解耦 消息的发送者无需知道消息使用者的存在 反之亦然
他可以使对应的客户端client与对应的消息中间件broker进行交互 消息中间件从发布者publisher 那里接收消息(发布消息的应用 也称为producer) 然后将他们转发给消费者(consumers)消息处理应用 由于amqp是一个网络协议 所以发布者 消费者以及消息中间件可以部署到不同的物理机器上面
消息中间件是一种由消息传送机制或者消息队列模式组成的中间件技术 利用高效可靠的消息传递机制进行平台无关的数据交流 并给予数据通信来进行分布式系统的集成
对于一个数据从生产到消费的正确传递 还有三个概念 exchange queues bindings
消息交换机 他指定消息按什么规则路由到哪个队列
消息队列载体 每个消息都会被投入到一个或多个队列
绑定 它的作用就是把exchange和queue按照路由规则绑定起来
Routing key 路由关键字 exchange根据这个关键字进行消息投递
Connection 就是一个tcp的连接 producer和consumer都是通过tcp连接到rabbitmq server的 以后我们可以看到 程序的起始处就是建立这个tcp连接
Channel 虚拟连接 他建立在上述的tcp连接中 数据流动都是在channel中进行的 也就是说 一般情况是程序起始建立tcp连接第二步就是建立这个channel
Vhost 虚拟主机 一个broker里可以开设多个vhost 用作不同用户的权限分离 每个virtual host本质上都是一个rabbitmq server 拥有它自己的queue exchange 和bings rule等保证了可以在多个不同的application中使用rabbitmq

rabbitmq-plugins enable rabbitmq_management 启动命令



5.Nginx

正向代理的代理对象是客户端,反向代理的代理对象是服务端
正向代理 代理的是客户端 例 找人海外代购 代购人是服务于你的 商店只知道卖给了代购人 而不知道真正买的人
反向代理 代理的是服务器 上网买鞋子 看好款式 价格 大小 后下单 店铺会代理到离地址近的仓库发货 你并不知道是哪个仓库发货 你只要看东西是否合适 


反向代理的好处 
保护了真实的web服务器 web服务器对外不可见 外网只能看到反向代理服务器 而反向代理服务器上没有真实的数据 因此 保证了web服务器的资源安全
反向代理为基础产生了动静资源分离以及负载均衡的方式 减轻web服务器的负担 加速了对网站访问的速度
节约了有限的IP地址资源 企业内所有的网站共享一个internent中注册的IP地址 这些服务器分配私有地址 采用虚拟主机的方式对外提供服务
    location / {
        root /home/receng-music/RecEng-front/dist/;
        index musicIndex.html;
    }
		
    location /api/receng/ {
         add_header 'Access-Control-Allow-Origin' '$http_origin' always;
            add_header 'Access-Control-Allow-Credentials' 'true' always;
            add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS,PUT,DELETE' always;
            add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range' always;
            add_header 'Access-Control-Expose-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range' always;

            if ($request_method = 'OPTIONS') {
                add_header 'Access-Control-Allow-Origin' '$http_origin' always;
                add_header 'Access-Control-Allow-Credentials' 'true' always;
                add_header 'Access-Control-Allow-Methods' 'GET,POST,OPTIONS,PUT,DELETE' always;
                add_header 'Access-Control-Allow-Headers' 'Pragma,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range' always;
                add_header 'Access-Control-Expose-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Content-Range,Range' always;
                add_header 'Access-Control-Max-Age' '1728000' always;
                add_header 'Content-Type' 'text/plain; charset=utf-8' always;
                add_header 'Content-Length' 0 always;
                return 204;
            }
            proxy_pass http://10.1.62.57:8101/;
    }

Nginx优点
可以高并发连接
官方测试nginx能够支撑5w并发 实际生产环境能够支撑2-4w并发
Nginx使用最新的epoll(Linux2.6内核)和kqueue网路io模型 而Apache使用的是传统select模型 其中比较稳定的prefork模式为多进程模型 需要经常派生子进程 所以消耗的CPU等服务器资源要比nginx多
内存消耗小
便宜
配置简单
支持rewrite重写
内置的健康检查功能
节省带宽
稳定性好


redis
    
    持久化
    redis支持持久化 通过持久化机制把内存中的数据同步到硬盘文件来保证数据持久化 当redis重启后通过把硬盘文件重新加载
    到内存 就能达到数据恢复的目的
    单独fork一个子进程 将当前父进程数据库数据复制到子进程的内存中 由子进程写到临时文件 再用临时文件替换之前的快照 
    持久化结束 子进程退出 内存释放
    rdb
    redis默认的持久化方式 按照一定的时间策略将数据库数据以快照的形式进行备份 产生dump.rdb文件 通过配置文件中
    save参数进行对周期的控制
    aof
    以日志的形式持久化数据 每当有写操作时 将命令写到文件最后
    
    缓存雪崩
    原有缓存数据失效 新的缓存数据还没有
    在此期间会有大量的请求 由原来的访问缓存数据库而转变为直接去查数据库 导致数据库 CPU和内存压力瞬间暴涨 有可能导致服务宕机
    加锁 不让太多的请求同时访问存储数据库
    
    缓存穿透
    用户查数据的时候 数据库没有 缓存自然也没有 两次无用查询
    布隆过滤器 将所有坑你存在的数据哈希到一个足够大的bitmap中 一个一定不存在的数据会被bitmap拦截
    (布隆过滤器是一种比较巧妙的数据结构 可以告诉你可能存在或一定不存在,占用空间较少 无法返回准确性信息)
    缓存击穿
    指一个key非常热点 大并发集中对这个key进行访问 这个key失效的瞬间 仍然持续的大并发访问穿破缓存 直接请求数据库
    缓存预热
    系统上线后 将一些缓存数据 先写到缓存数据库
    
    
    
    
    
    
    
    
    
    
    
    
    
    